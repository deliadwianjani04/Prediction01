{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba84ce1",
   "metadata": {},
   "source": [
    "\n",
    "# Prediksi Risiko Stroke dengan Jaringan Saraf Tiruan + Antarmuka Streamlit\n",
    "\n",
    "Notebook ini membangun model **Jaringan Saraf Tiruan (Artificial Neural Network / ANN)**  \n",
    "untuk memprediksi risiko stroke menggunakan **dataset stroke**, lalu menyiapkan kode\n",
    "**antarmuka Streamlit** seperti contoh sistem pendukung keputusan penyakit jantung\n",
    "(dengan slider dan dropdown).\n",
    "\n",
    "## Alur Notebook\n",
    "\n",
    "1. Import library & load dataset stroke.  \n",
    "2. Eksplorasi singkat & penanganan *missing value*.  \n",
    "3. Pra-pemrosesan data (encoding kategorik + scaling numerik).  \n",
    "4. Split data menjadi train / test.  \n",
    "5. Membangun & melatih model **ANN (MLPClassifier)**.  \n",
    "6. Evaluasi model (akurasi, confusion matrix, ROC-AUC).  \n",
    "7. Menyimpan model terlatih ke file `.pkl`.  \n",
    "8. Contoh kode **Streamlit** dengan slider & selectbox untuk prediksi stroke secara interaktif.\n",
    "\n",
    "> Semua bagian kode diberi komentar dan penjelasan dalam bahasa Indonesia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda645d6",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Import Library dan Load Dataset Stroke\n",
    "\n",
    "Pada bagian ini:\n",
    "- Kita mengimpor library yang diperlukan.  \n",
    "- Membaca dataset stroke dari file `.csv`.  \n",
    "- Menampilkan beberapa baris teratas untuk melihat struktur data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import library dasar untuk analisis dan visualisasi data\n",
    "import pandas as pd          # untuk manipulasi data berbasis tabel\n",
    "import numpy as np           # untuk perhitungan numerik\n",
    "import matplotlib.pyplot as plt  # untuk visualisasi (jika dibutuhkan)\n",
    "\n",
    "# Agar grafik muncul langsung di notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Path dataset stroke (file sudah di-upload)\n",
    "csv_path = \"/mnt/data/healthcare-dataset-stroke-data.csv\"\n",
    "\n",
    "# Membaca dataset ke DataFrame pandas\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Menampilkan 5 baris pertama untuk melihat struktur kolom\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20535c16",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Eksplorasi Data & Cek Missing Value\n",
    "\n",
    "Kita perlu memahami:\n",
    "- Tipe data tiap kolom.  \n",
    "- Distribusi dasar dari fitur numerik.  \n",
    "- Apakah ada nilai kosong (*missing values*).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c17e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Informasi struktur data: jumlah baris/kolom dan tipe data\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ringkasan statistik dasar untuk kolom numerik\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b27fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mengecek jumlah nilai kosong pada setiap kolom\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f3bb9",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Menangani Missing Value pada `bmi`\n",
    "\n",
    "Biasanya kolom `bmi` memiliki beberapa nilai kosong (`NaN`).  \n",
    "Strategi sederhana yang digunakan:\n",
    "- Mengisi `NaN` dengan **median** kolom `bmi`.  \n",
    "  - Median cukup *robust* terhadap outlier.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13141c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Menghitung median untuk kolom 'bmi'\n",
    "bmi_median = df['bmi'].median()\n",
    "\n",
    "# Mengisi nilai NaN pada 'bmi' dengan median\n",
    "df['bmi'] = df['bmi'].fillna(bmi_median)\n",
    "\n",
    "# Memastikan tidak ada lagi nilai kosong di kolom 'bmi'\n",
    "df['bmi'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df4a83",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Menentukan Fitur (X) dan Target (y)\n",
    "\n",
    "- **Target (y)**: kolom `stroke`  \n",
    "  - `1` ‚Üí pasien mengalami stroke / berisiko stroke.  \n",
    "  - `0` ‚Üí tidak stroke.  \n",
    "\n",
    "- **Fitur (X)**: semua kolom selain `id` dan `stroke`.  \n",
    "  - Kolom `id` hanya sebagai identitas unik ‚Üí dibuang.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fca35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Menghapus kolom 'id' karena tidak informatif untuk prediksi\n",
    "df_model = df.drop(columns=['id'])\n",
    "\n",
    "# Memisahkan fitur (X) dan target (y)\n",
    "X = df_model.drop(columns=['stroke'])\n",
    "y = df_model['stroke']\n",
    "\n",
    "# Menampilkan nama-nama kolom fitur\n",
    "X.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa460c8c",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Memisahkan Fitur Numerik dan Kategorik\n",
    "\n",
    "Supaya pra-pemrosesan lebih rapi:\n",
    "- Fitur **numerik** akan di-*scale* dengan `StandardScaler`.  \n",
    "- Fitur **kategorik** akan di-*encode* dengan `OneHotEncoder`.  \n",
    "\n",
    "Contoh di dataset stroke:\n",
    "- Numerik: `age`, `avg_glucose_level`, `bmi`.  \n",
    "- Kategorik: `gender`, `ever_married`, `work_type`, `Residence_type`, `smoking_status`.  \n",
    "  (Kolom 0/1 seperti `hypertension` dan `heart_disease` tetap dianggap numerik sederhana).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60095a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Menentukan fitur numerik dan kategorik\n",
    "numeric_features = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "# Fitur lain (selain target dan numerik) kita perlakukan sebagai kategorik\n",
    "all_features = list(X.columns)\n",
    "categorical_features = [col for col in all_features if col not in numeric_features]\n",
    "\n",
    "numeric_features, categorical_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea7a6f",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Pra-pemrosesan & Model ANN dalam Pipeline\n",
    "\n",
    "Kita menggunakan `ColumnTransformer` dan `Pipeline` dari scikit-learn:\n",
    "\n",
    "- `ColumnTransformer`:\n",
    "  - Menerapkan `StandardScaler` ke fitur numerik.\n",
    "  - Menerapkan `OneHotEncoder` ke fitur kategorik.\n",
    "\n",
    "- `Pipeline`:\n",
    "  - Langkah 1: pra-pemrosesan (`ColumnTransformer`).  \n",
    "  - Langkah 2: model **ANN** (`MLPClassifier`).  \n",
    "\n",
    "Dengan cara ini, semua proses (encoding, scaling, training) terbungkus rapi dalam satu objek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599117f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Transformer untuk fitur numerik: standarisasi\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Transformer untuk fitur kategorik: One-Hot Encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Menggabungkan keduanya dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d09cb",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Membagi Data Menjadi Train dan Test\n",
    "\n",
    "Untuk mengukur performa model pada data yang belum dilihat, kita membagi data:\n",
    "\n",
    "- 80% ‚Üí data latih (`train`).  \n",
    "- 20% ‚Üí data uji (`test`).  \n",
    "\n",
    "Kita gunakan `stratify=y` agar proporsi kelas (0 dan 1) tetap seimbang di train dan test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data menjadi train dan test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca17eef",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Membangun Model Jaringan Saraf Tiruan (MLPClassifier)\n",
    "\n",
    "Kita gunakan `MLPClassifier` dengan konfigurasi:\n",
    "\n",
    "- `hidden_layer_sizes=(32, 16)` ‚Üí 2 hidden layer (32 neuron & 16 neuron).  \n",
    "- `activation='relu'` ‚Üí fungsi aktivasi ReLU.  \n",
    "- `solver='adam'` ‚Üí optimizer Adam.  \n",
    "- `max_iter=300` ‚Üí maksimal 300 iterasi training.  \n",
    "\n",
    "Model ini digabung dengan `preprocessor` dalam `Pipeline` bernama `clf`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definisi model ANN (MLPClassifier)\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(32, 16),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Pipeline: pra-pemrosesan + model ANN\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', mlp_clf)\n",
    "])\n",
    "\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334f67de",
   "metadata": {},
   "source": [
    "\n",
    "### 6.1 Melatih Model ANN\n",
    "\n",
    "Sekarang kita latih model pada data train (`X_train`, `y_train`).  \n",
    "Pra-pemrosesan (scaling + encoding) akan otomatis dijalankan di dalam `Pipeline`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e35170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Melatih model\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953cb72",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Evaluasi Model\n",
    "\n",
    "Kita hitung:\n",
    "- Akurasi pada data train dan test.  \n",
    "- Confusion Matrix dan Classification Report pada data test.  \n",
    "- Nilai ROC-AUC dan kurva ROC.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prediksi pada data train dan test\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Akurasi\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Akurasi data latih :\", train_acc)\n",
    "print(\"Akurasi data uji   :\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix & classification report untuk data uji\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "report = classification_report(y_test, y_test_pred, digits=3)\n",
    "\n",
    "print(\"Confusion Matrix (data uji):\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report (data uji):\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e87fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ROC-AUC dan kurva ROC\n",
    "y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "print(\"ROC-AUC (data uji):\", roc_auc)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Kurva ROC - Prediksi Stroke (ANN)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c78064",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Menyimpan Model ke File `.pkl`\n",
    "\n",
    "Agar bisa dipakai oleh aplikasi **Streamlit**, model `clf` (Pipeline lengkap)\n",
    "akan disimpan ke file dengan format pickle (`.pkl`) menggunakan `joblib`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "# Menyimpan pipeline + model ke file\n",
    "model_path = \"stroke_ann_pipeline.pkl\"\n",
    "joblib.dump(clf, model_path)\n",
    "\n",
    "model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f058d6",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Kode Aplikasi Streamlit (UI Slider & Dropdown)\n",
    "\n",
    "Bagian ini berisi **contoh kode Streamlit** sehingga tampilannya mirip dengan\n",
    "_Sistem Penunjang Keputusan_ untuk penyakit jantung yang menggunakan slider dan dropdown.\n",
    "\n",
    "### Cara Pakai\n",
    "\n",
    "1. Pastikan file model `stroke_ann_pipeline.pkl` sudah dibuat oleh notebook ini.  \n",
    "2. Buat file Python baru, misalnya **`app_stroke.py`**.  \n",
    "3. Salin kode di bawah ke dalam `app_stroke.py`.  \n",
    "4. Di terminal, jalankan:\n",
    "\n",
    "```bash\n",
    "streamlit run app_stroke.py\n",
    "```\n",
    "\n",
    "5. Browser akan terbuka menampilkan form input (umur, jenis kelamin, hipertensi, dll) dan tombol prediksi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======== KODE UNTUK FILE: app_stroke.py ========\n",
    "# Jika dijalankan di notebook, kode ini hanya sebagai contoh teks.\n",
    "# Untuk benar-benar menjalankan Streamlit:\n",
    "# 1. Salin kode ini ke file baru bernama `app_stroke.py`\n",
    "# 2. Jalankan: streamlit run app_stroke.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Memuat model pipeline yang sudah dilatih\n",
    "model = joblib.load(\"stroke_ann_pipeline.pkl\")\n",
    "\n",
    "st.title(\"üß† Sistem Penunjang Keputusan Prediksi Stroke\")\n",
    "\n",
    "st.markdown(\"Masukkan data pasien pada form berikut, lalu klik **Prediksi**.\")\n",
    "\n",
    "# --- Input fitur dengan slider dan dropdown ---\n",
    "\n",
    "# Umur\n",
    "age = st.slider(\"Umur\", min_value=0, max_value=100, value=45)\n",
    "\n",
    "# Jenis kelamin (sesuaikan dengan kategori di dataset: 'Male', 'Female', 'Other')\n",
    "gender = st.selectbox(\"Jenis Kelamin\", [\"Male\", \"Female\", \"Other\"])\n",
    "\n",
    "# Hipertensi (0 = tidak, 1 = ya)\n",
    "hypertension_label = st.selectbox(\"Hipertensi\", [\"Tidak\", \"Ya\"])\n",
    "hypertension = 1 if hypertension_label == \"Ya\" else 0\n",
    "\n",
    "# Penyakit jantung (0 = tidak, 1 = ya)\n",
    "heart_label = st.selectbox(\"Penyakit Jantung\", [\"Tidak\", \"Ya\"])\n",
    "heart_disease = 1 if heart_label == \"Ya\" else 0\n",
    "\n",
    "# Pernah menikah\n",
    "ever_married = st.selectbox(\"Status Pernikahan\", [\"Yes\", \"No\"])\n",
    "\n",
    "# Tipe pekerjaan (sesuai dataset)\n",
    "work_type = st.selectbox(\n",
    "    \"Jenis Pekerjaan\",\n",
    "    [\"Private\", \"Self-employed\", \"Govt_job\", \"children\", \"Never_worked\"]\n",
    ")\n",
    "\n",
    "# Tipe tempat tinggal\n",
    "Residence_type = st.selectbox(\n",
    "    \"Tipe Tempat Tinggal\",\n",
    "    [\"Urban\", \"Rural\"]\n",
    ")\n",
    "\n",
    "# Rata-rata kadar glukosa\n",
    "avg_glucose_level = st.slider(\n",
    "    \"Rata-rata Kadar Glukosa\",\n",
    "    min_value=50.0, max_value=300.0, value=120.0\n",
    ")\n",
    "\n",
    "# BMI\n",
    "bmi = st.slider(\n",
    "    \"BMI (Body Mass Index)\",\n",
    "    min_value=10.0, max_value=60.0, value=25.0\n",
    ")\n",
    "\n",
    "# Status merokok (sesuai dataset)\n",
    "smoking_status = st.selectbox(\n",
    "    \"Status Merokok\",\n",
    "    [\"formerly smoked\", \"never smoked\", \"smokes\", \"Unknown\"]\n",
    ")\n",
    "\n",
    "# Tombol prediksi\n",
    "if st.button(\"Prediksi Risiko Stroke\"):\n",
    "    # Menyusun data input ke dalam DataFrame satu baris\n",
    "    input_dict = {\n",
    "        \"gender\": [gender],\n",
    "        \"age\": [age],\n",
    "        \"hypertension\": [hypertension],\n",
    "        \"heart_disease\": [heart_disease],\n",
    "        \"ever_married\": [ever_married],\n",
    "        \"work_type\": [work_type],\n",
    "        \"Residence_type\": [Residence_type],\n",
    "        \"avg_glucose_level\": [avg_glucose_level],\n",
    "        \"bmi\": [bmi],\n",
    "        \"smoking_status\": [smoking_status],\n",
    "    }\n",
    "\n",
    "    input_df = pd.DataFrame(input_dict)\n",
    "\n",
    "    # Menggunakan model pipeline untuk prediksi\n",
    "    pred = model.predict(input_df)[0]\n",
    "    proba = model.predict_proba(input_df)[0, 1]\n",
    "\n",
    "    st.subheader(\"Hasil Prediksi\")\n",
    "\n",
    "    if pred == 1:\n",
    "        st.error(f\"‚ö†Ô∏è Pasien **BERISIKO STROKE**.\\n\\nProbabilitas stroke: **{proba:.2%}**\")\n",
    "    else:\n",
    "        st.success(f\"‚úÖ Pasien **TIDAK BERISIKO STROKE** (menurut model).\\n\\nProbabilitas stroke: **{proba:.2%}**\")\n",
    "\n",
    "    st.caption(\"Catatan: Ini hanya model pembelajaran mesin sebagai contoh akademik, \"\n",
    "               \"bukan pengganti diagnosa dokter.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca6eb7",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Ringkasan\n",
    "\n",
    "Di notebook ini, kita telah:\n",
    "\n",
    "1. Mengolah dataset stroke (mengisi `bmi` yang kosong).  \n",
    "2. Menyiapkan fitur numerik dan kategorik, lalu melakukan scaling & encoding.  \n",
    "3. Membangun dan melatih model **Jaringan Saraf Tiruan (ANN)** dengan `MLPClassifier`.  \n",
    "4. Mengevaluasi performa model dengan berbagai metrik (akurasi, ROC-AUC).  \n",
    "5. Menyimpan pipeline + model ke file `stroke_ann_pipeline.pkl`.  \n",
    "6. Menyusun kode aplikasi **Streamlit** dengan slider dan dropdown sehingga bisa menjadi\n",
    "   **Sistem Penunjang Keputusan Prediksi Stroke** seperti contoh penyakit jantung yang kamu kirim.\n",
    "\n",
    "Kamu bisa menyesuaikan teks, tampilan, bahkan menambah grafik/gauge di Streamlit sesuai kebutuhan skripsi atau proyekmu. üí°\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
